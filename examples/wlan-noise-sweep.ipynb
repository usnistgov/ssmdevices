{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Acquisition Example: Testing WLAN Client Receiver System Noise\n",
    "\n",
    "Test data for WLAN is implemented with the the iperf support in [ssmdevices](https://gitlab.nist.gov/ssm/ssmdevices). It produces many more columns of data than we need, so we just use the two defined in `ipc_columns`: throughput and a timestamp.\n",
    "\n",
    "The results of the tests and the corresponding test conditions are stored in a [flat database](https://en.wikipedia.org/wiki/Flat_file_database) stored in SQLite format. It is implemented as a typical intended use case of `labbench.RelationalDataInSQLite`. The test conditions are implemented as states in the attenuators, `iperf`, and `wlan`, so all we need to log these results into the database is to add the `db.on_set` call. Any states that are changed after that function call (for example, with the for loops in the acquisition code) become columns in the database; these values are automatically kept up to date and written to the database on calls to `db.write`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2018-11-01 11:43:31.178\u001b[0m - \u001b[30mINFO\u001b[0m - Connected in 1.06s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ddfb0b994c04d23ad2cb6583def9369",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tab(children=(VBox(children=(HBox(children=(HBox(children=(HTML(value=''),)), HBox(children=(HTML(value=''),))â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dkuester\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\api.py:107: RuntimeWarning: '<' not supported between instances of 'str' and 'int', sort order is undefined for incomparable objects\n",
      "  result = result.union(other)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "781d521a85df4900892c8bcf577a6227",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value=''), IntProgress(value=0, max=6)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dkuester\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:6201: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=True'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass sort=False\n",
      "\n",
      "  sort=sort)\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "the feather-format library is not installed\nyou can install via conda\nconda install feather-format -c conda-forge\nor via pip\npip install -U feather-format\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\io\\feather_format.py\u001b[0m in \u001b[0;36m_try_import\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[1;32mimport\u001b[0m \u001b[0mfeather\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'feather'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-861cbbf426a7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    135\u001b[0m                 \u001b[0mtestbed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwlan\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m                 \u001b[0mtestbed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 137\u001b[1;33m                 \u001b[0mtestbed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\labbench\\util.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1104\u001b[0m             \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__cm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__exit__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1105\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mex\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1106\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mex\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1107\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\labbench\\util.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1096\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1097\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcleanup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m             \u001b[0mex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-861cbbf426a7>\u001b[0m in \u001b[0;36mcleanup\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    109\u001b[0m                                 target_cols=['iperf_destination_address','iperf_destination_port', 'iperf_bits_per_second', 'iperf_timestamp'],)\n\u001b[0;32m    110\u001b[0m         \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'summary.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m         \u001b[0mlb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_feather\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'summary.feather'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m         \u001b[0mlb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'finished with testbed after {}s'\u001b[0m                       \u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\labbench\\data.py\u001b[0m in \u001b[0;36mto_feather\u001b[1;34m(data, path)\u001b[0m\n\u001b[0;32m    933\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    934\u001b[0m         \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 935\u001b[1;33m         \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_feather\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    936\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    937\u001b[0m         \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mto_feather\u001b[1;34m(self, fname)\u001b[0m\n\u001b[0;32m   1887\u001b[0m         \"\"\"\n\u001b[0;32m   1888\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeather_format\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mto_feather\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1889\u001b[1;33m         \u001b[0mto_feather\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1891\u001b[0m     def to_parquet(self, fname, engine='auto', compression='snappy',\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\io\\feather_format.py\u001b[0m in \u001b[0;36mto_feather\u001b[1;34m(df, path)\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"feather only support IO with DataFrames\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m     \u001b[0mfeather\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_try_import\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m     \u001b[0mvalid_types\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'string'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'unicode'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\io\\feather_format.py\u001b[0m in \u001b[0;36m_try_import\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[1;31m# give a nice error message\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         raise ImportError(\"the feather-format library is not installed\\n\"\n\u001b[0m\u001b[0;32m     19\u001b[0m                           \u001b[1;34m\"you can install via conda\\n\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m                           \u001b[1;34m\"conda install feather-format -c conda-forge\\n\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: the feather-format library is not installed\nyou can install via conda\nconda install feather-format -c conda-forge\nor via pip\npip install -U feather-format\n"
     ]
    }
   ],
   "source": [
    "# This should be run in python 3.6.x from the computer connected to the AP side\n",
    "\n",
    "%pylab inline\n",
    "import time,os\n",
    "import ssmdevices as ssm\n",
    "import labbench as lb\n",
    "import pandas as pd\n",
    "\n",
    "def meshpoints (x1, x2, *args):\n",
    "    ''' For input of N-dimensions of grid point vectors (x1, x2, ..., xN),\n",
    "        where each (x1, x2, ... xN) has dimension (M1, M2, ..., MN),\n",
    "        returns an array with shape (M1*M2*...*MN,N) that consists of the\n",
    "        unique points in the multi-dimensional grid with sampled at\n",
    "        the vector points (x1, x2, ..., xN) in each axis. This is also known\n",
    "        as the the cartesian product of (x1 ... xN).\n",
    "    '''\n",
    "    ret = np.array(np.meshgrid(*((x1,x2)+args)))\n",
    "    return ret.reshape([ret.shape[0],np.prod(ret.shape[1:])]).T\n",
    "\n",
    "setup_time = 5 # seconds\n",
    "acquisition_time = 1 #  seconds\n",
    "\n",
    "# iperf_columns       = ['iperf_bits_per_second','iperf_timestamp']\n",
    "sweep_points       = meshpoints(list(range(55,76,20)),[110]+list(range(0,21,20)))\n",
    "\n",
    "lb.show_messages('info')\n",
    "\n",
    "class Testbed(lb.Testbed):       \n",
    "    def make(self):\n",
    "        ''' lb.Testbed calls this automatically when we call Testbed(config)\n",
    "        '''\n",
    "        self.c = ssm.instruments.MiniCircuitsRCDAT('11604210008')\n",
    "        self.e0 = ssm.instruments.MiniCircuitsRCDAT('11604210014')\n",
    "        self.iperf_client = ssm.software.IPerf('10.0.0.2', bind='10.0.0.3', port=5010, interval=0.1)\n",
    "        self.iperf_server = ssm.software.IPerf(bind='10.0.0.2', port=5010)\n",
    "        self.wlan = ssm.software.WLANStatus('Wi-Fi', ssid='EnGenius1')\n",
    "        self.db = lb.StatesToSQLite(time.strftime(\"%Y-%m-%d-%H%M%S with shuffle and absorber\"))\n",
    "        self.dc_power = ssm.instruments.RigolDP800Series('USB0::0x1AB1::0x0E11::DP8C180200079::INSTR')\n",
    "\n",
    "        # Log all state changes in lte_laa and each client in iperf_clients\n",
    "        self.db.observe_states([self.c,self.e0,self.iperf_server,self.iperf_client,self.wlan])\n",
    "        \n",
    "    def acquire(self, duration):\n",
    "        ''' acquire for `duration` seconds and return a dictionary of\n",
    "            client and server data frames\n",
    "        '''\n",
    "        # Cycle through port in iperf server & client to avoid some strange\n",
    "        # errors involving stale ports in windows\n",
    "        p = self.iperf_server.settings.port\n",
    "        self.iperf_client.settings.port = self.iperf_server.settings.port = p+1            \n",
    "        \n",
    "        self.iperf_server.start()\n",
    "        self.iperf_client.start()\n",
    "\n",
    "        lb.logger.info('acquiring for {}s'.format(duration))\n",
    "        lb.sleep(setup_time)\n",
    "\n",
    "        client = self.iperf_client.fetch()\n",
    "        server = self.iperf_server.fetch()\n",
    "\n",
    "        lb.logger.debug('  iperf_client and server returned {} and {} rows'\\\n",
    "                       .format(len(client),len(server)))\n",
    "\n",
    "        self.iperf_server.kill()\n",
    "        self.iperf_client.kill()\n",
    "        \n",
    "        return {'iperf_client': client,\n",
    "                'iperf_server': server}\n",
    "\n",
    "    def startup(self):\n",
    "        lb.panel(self, ncols=6) # Heads-up display for the notebook\n",
    "        \n",
    "        # Noise source sanity checks\n",
    "        if not self.dc_power.state.enable1:\n",
    "            raise ValueError('noise source power supply is off. check voltage setting, connect, and turn on')\n",
    "        if self.dc_power.state.voltage1 < 10:\n",
    "            raise ValueError('noise source voltage supply setting is low, {}V'\\\n",
    "                             .format(self.dc_power.state.voltage1))\n",
    "        if self.dc_power.state.current1 < 0.07:\n",
    "            raise ValueError('noise source current draw is low, {}A. check connections'\\\n",
    "                             .format(self.dc_power.state.current1))\n",
    "        \n",
    "        lb.logger.info('setup start')\n",
    "        self.t0 = time.time()\n",
    "        \n",
    "        self.wlan.interface_disconnect()\n",
    "        \n",
    "        self.c.state.attenuation = 50\n",
    "        self.e0.state.attenuation = 110\n",
    "        \n",
    "        # Throwaway acquisition to get into a favorable state\n",
    "        self.acquire(setup_time)    \n",
    "        lb.logger.info('setup done')\n",
    "    \n",
    "    def cleanup(self):\n",
    "        # End any stale iperf processes in the correct order\n",
    "        self.iperf_server.kill()\n",
    "        self.iperf_client.kill()\n",
    "        \n",
    "        # Leave attenuators in a sensible state\n",
    "        self.c.state.attenuation = 50\n",
    "        self.e0.state.attenuation = 110\n",
    "        \n",
    "        # Load the sqlite database and save a copy into a csv\n",
    "        df = lb.read(os.path.join(self.db.path, 'master.db'))\n",
    "        df.to_csv(os.path.join(self.db.path,'master.csv'))\n",
    "        \n",
    "        # Flatten the iperf result\n",
    "        lb.logger.info('expanding iperf result into summary output')\n",
    "        df = lb.read_relational(os.path.join(self.db.path, 'master.db'),\n",
    "                                'iperf_client', prepend_column_name=False,\n",
    "                                target_cols=['iperf_destination_address','iperf_destination_port', 'iperf_bits_per_second', 'iperf_timestamp'],)\n",
    "        df.to_csv(os.path.join(self.db.path, 'summary.csv'))\n",
    "        lb.to_feather(df, os.path.join(self.db.path, 'summary.feather'))\n",
    "        \n",
    "        lb.logger.info('finished with testbed after {}s'\\\n",
    "                       .format(time.time()-self.t0))\n",
    "\n",
    "for i in range(1):\n",
    "    states = {}\n",
    "\n",
    "    np.random.shuffle(sweep_points)\n",
    "    \n",
    "    # This `with' block ensures sockets and iperf subprocesses are\n",
    "    # closed correctly when the script ends, even if exceptions are raised\n",
    "    with Testbed() as testbed:\n",
    "        for testbed.c.state.attenuation, testbed.e0.state.attenuation\\\n",
    "            in lb.log_progress(sweep_points):\n",
    "\n",
    "            try:\n",
    "                row = {}                \n",
    "                testbed.wlan.interface_reconnect(5)     # Fresh connection\n",
    "                row = testbed.acquire(acquisition_time)\n",
    "            except TimeoutError as e:\n",
    "                # Blank data\n",
    "                lb.logger.debug(str(e))\n",
    "                lb.logger.debug('No connection to AP - skipping data acquisition')\n",
    "            finally:\n",
    "                # Update all WLAN states before append \n",
    "                testbed.wlan.refresh()\n",
    "                testbed.db.append(row)\n",
    "                testbed.db.write()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testbed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = lb.read(r'C:/Users/dkuester/Documents/src/ssmdevices/examples/2018-10-30-141739 with shuffle and absorber/master.db')\n",
    "df2 = lb.read(r'C:\\Users\\dkuester\\Documents\\src\\ssmdevices\\examples\\2018-10-30-154819 with shuffle and absorber\\master.db')\n",
    "\n",
    "df=df.sort_values(['c_attenuation','e0_attenuation'])\n",
    "df2=df2.sort_values(['c_attenuation','e0_attenuation'])\n",
    "df=df.set_index(['c_attenuation','e0_attenuation'])\n",
    "df2=df2.set_index(['c_attenuation','e0_attenuation'])\n",
    "\n",
    "# i = (df['wlan_state']=='connected')&(df2['wlan_state']=='connected')\n",
    "\n",
    "(df['wlan_signal']-df2['wlan_signal']).hist(bins=20)\n",
    "print((df[i]['wlan_signal']-df2[i]['wlan_signal']).mad())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "\n",
    "w1 = widgets.IntSlider()\n",
    "w2 = widgets.IntSlider()\n",
    "tab = widgets.Tab([w1,w2])\n",
    "tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab.close_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in tab.children:\n",
    "    c.close_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab.children = w1, w2\n",
    "display(tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import labbench as lb\n",
    "import importlib\n",
    "lb = importlib.reload(lb)\n",
    "\n",
    "path = r'C:/Users/dkuester/Documents/src/ssmdevices/examples/2018-10-30-141739 with shuffle and absorber/master.db'\n",
    "df = lb.read_relational(path, 'iperf_client', prepend_column_name=False,\n",
    "                        target_cols=['iperf_destination_address','iperf_destination_port', 'iperf_bits_per_second', 'iperf_timestamp'],)\n",
    "df.to_csv(os.path.join(os.path.dirname(path), 'summary.csv'))\n",
    "lb.to_feather(df, os.path.join(os.path.dirname(path), 'summary.feather'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb.read(r'C:\\Users\\dkuester\\Documents\\src\\ssmdevices\\examples\\2018-10-30-154819 with shuffle and absorber\\0 2018-10-30 154837.796099\\iperf_client.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.sort_values(['c_attenuation','e0_attenuation'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
